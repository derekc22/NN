specs:
  device_type: "cpu"
  input_feature_count: 1
  stateful: true

#------------------------------------------------------------------------------------------------------------------------
train:
  epochs: 1000
  train_dataset_size: 500
  show_loss_plot: true

hyperparameters:
    learn_rate: 0.01
    batch_size: 64 # Keep this as None to avoid shuffling data. temporal relationships are important in RNNs
    loss_func: "SSELoss"
    reduction: "mean"
    optimizer: "adam"
    lambda_L2: ~ # 0.0001
    dropout_rate: ~
    grad_clip_norm: ~ #5   # e.g. limit global norm to 5
    grad_clip_value: ~ #0.1  # e.g. clamp each grad element to Â±0.1

architecture:
    # hidden_state_neuron_counts: [16, 32, 64]
    hidden_state_neuron_counts: [64]
    output_feature_count: 1
    hidden_activation_function: "sigmoid"
    output_activation_function: "none"

#------------------------------------------------------------------------------------------------------------------------
test:
  test_dataset_size: 50

parameters_fpath: "./params/paramsRNN"

